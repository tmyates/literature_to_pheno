{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:12:18.169504Z",
     "start_time": "2021-12-19T11:12:16.331244Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:12:18.508428Z",
     "start_time": "2021-12-19T11:12:18.170834Z"
    }
   },
   "outputs": [],
   "source": [
    "# load retrieved_df2 from cadmus output\n",
    "retrieved_df = pickle.load(open('retrieved_df2.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T09:49:34.162234Z",
     "start_time": "2021-12-03T09:49:33.545288Z"
    }
   },
   "outputs": [],
   "source": [
    "# hp terms with commas in - cause issues with splitting trigger\n",
    "hp_commas = pickle.load(open('hp_commas.p','rb'))\n",
    "\n",
    "# mappings from cui to hpo using mrconso file\n",
    "cui_mapped = pickle.load(open('cui_fully_mapped.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T09:49:34.284779Z",
     "start_time": "2021-12-03T09:49:34.206241Z"
    }
   },
   "outputs": [],
   "source": [
    "def hp_from_lst(hp):\n",
    "    if type(hp)==list:\n",
    "        return(hp[0])\n",
    "    else:\n",
    "        return hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T09:49:34.368922Z",
     "start_time": "2021-12-03T09:49:34.312815Z"
    }
   },
   "outputs": [],
   "source": [
    "cui_mapped['hpo_id'] = cui_mapped['hpo_id'].apply(hp_from_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T09:49:35.053797Z",
     "start_time": "2021-12-03T09:49:35.041117Z"
    }
   },
   "outputs": [],
   "source": [
    "def mm_list_to_dict(mm_outfile_path, file_id):\n",
    "    mm_dicts = []\n",
    "    with open(mm_outfile_path,'r') as f:\n",
    "        mm_outfile = f.readlines()\n",
    "#         check for files where mm hasn't worked\n",
    "        if len(mm_outfile) >1:\n",
    "            \n",
    "            # lose first item as this is artefact\n",
    "            mm_outfile = mm_outfile[1:]\n",
    "            mm_outfile = [i.split('|') for i in mm_outfile]\n",
    "            for i in mm_outfile:\n",
    "                try:\n",
    "                    if i[1] == 'MMI':\n",
    "                        try:\n",
    "                            mm_dicts.append({'id':file_id,\n",
    "                                             'mmi':i[1],\n",
    "                                             'score':i[2],\n",
    "                                             'preferred_name':i[3],\n",
    "                                             'cui':i[4], \n",
    "                                             'sem_type_list':i[5], \n",
    "                                             'trigger':i[6], \n",
    "                                             'location':i[7], \n",
    "                                             'pos':i[8]})\n",
    "                        except:\n",
    "                            mm_dicts.append({'id':file_id,\n",
    "                                             'mmi':0,\n",
    "                                             'score':0,\n",
    "                                             'preferred_name':0,\n",
    "                                             'cui':0, \n",
    "                                             'sem_type_list':0, \n",
    "                                             'trigger':0, \n",
    "                                             'location':0, \n",
    "                                             'pos':0})\n",
    "                except:\n",
    "                    mm_dicts.append({'id':file_id,\n",
    "                                             'mmi':0,\n",
    "                                             'score':0,\n",
    "                                             'preferred_name':0,\n",
    "                                             'cui':0, \n",
    "                                             'sem_type_list':0, \n",
    "                                             'trigger':0, \n",
    "                                             'location':0, \n",
    "                                             'pos':0})\n",
    "                    \n",
    "\n",
    "        else:\n",
    "             mm_dicts.append({'id':file_id,\n",
    "                              'mmi':0,\n",
    "                              'score':0,\n",
    "                              'preferred_name':0,\n",
    "                              'cui':0,\n",
    "                              'sem_type_list':0,\n",
    "                              'trigger':0,\n",
    "                              'location':0,\n",
    "                              'pos':0})\n",
    "    \n",
    "    # substitute triggers which include commas to allow split of trigger list\n",
    "    for i in mm_dicts:\n",
    "        if i['cui'] in hp_cui:\n",
    "            for j in range(len(hp_commas)):\n",
    "                try:\n",
    "                    if i['trigger'] != 0:\n",
    "                        com = hp_commas['hp_label'].iloc[j]\n",
    "                        nocom = hp_commas['hp_label_no_comma'].iloc[j]\n",
    "                        for k,v in i.items():\n",
    "                            if com in v:\n",
    "                                i[k] = re.sub(com, nocom, v)\n",
    "                except: \n",
    "                    com = hp_commas['hp_label'].iloc[j]\n",
    "                    nocom = hp_commas['hp_label_no_comma'].iloc[j]\n",
    "\n",
    "                    \n",
    "    for i in mm_dicts:\n",
    "        try:\n",
    "            i['trigger'] = i['trigger'][1:-1].split(\",\")\n",
    "        except:\n",
    "            i['trigger'] = 0\n",
    "\n",
    "                \n",
    "    for i in mm_dicts:\n",
    "\n",
    "        if i['trigger'] == 0:\n",
    "            i['match_freq'] = 0\n",
    "            i['neg_freq'] = 0\n",
    "        \n",
    "        else:\n",
    "            match_freq = 0\n",
    "            neg_freq = 0\n",
    "            for k in i['trigger']:\n",
    "                if k.endswith(\"0\"):\n",
    "                    match_freq += 1\n",
    "                elif k.endswith(\"1\"):\n",
    "                    neg_freq += 1\n",
    "            i['match_freq'] = match_freq\n",
    "            i['neg_freq'] = neg_freq\n",
    "        \n",
    "    return mm_dicts\n",
    "            \n",
    "def all_mm_output(mm_output_dirpath):\n",
    "    mm_output_dir = Path(mm_output_dirpath)\n",
    "    mm_output_paths = [i for i in mm_output_dir.glob('*.out')]\n",
    "    \n",
    "    all_mm = []\n",
    "    for output_path in mm_output_paths:\n",
    "        file_id = output_path.stem\n",
    "        mm_filepath = str(output_path)\n",
    "        mm_dicts = mm_list_to_dict(mm_filepath, file_id)\n",
    "        all_mm = all_mm + mm_dicts\n",
    "        \n",
    "    return all_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T09:56:33.208486Z",
     "start_time": "2021-12-03T09:56:33.195573Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_mm_cui(mm_output_dirpath):\n",
    "    mm_df = pd.DataFrame(all_mm_output(mm_output_dirpath))\n",
    "    mm_df['source']='HPO'\n",
    "    mm_map = mm_df.merge(cui_mapped, left_on='cui', right_index=True, how='left')\n",
    "    mm_map = mm_map.rename(columns={'hpo_id':'source_id'})\n",
    "\n",
    "    return mm_map\n",
    "\n",
    "# output_type is str e.g. tiab, content, technical text\n",
    "def freq_per_paper_mm(mm_output_dirpath, output_type):\n",
    "    mm_map = map_mm_cui(mm_output_dirpath)\n",
    "    paper_ids = list(set(mm_map['id']))\n",
    "    pid_freq = []\n",
    "    for pid in paper_ids:\n",
    "        paper_df = mm_map[mm_map['id']==pid]\n",
    "        hpo_df = paper_df[paper_df['source']=='HPO']\n",
    "        hp_lst = list(zip(hpo_df['source_id'],hpo_df['match_freq']))\n",
    "        hgnc_df = paper_df[paper_df['source']=='HGNC']\n",
    "        hgnc_lst = list(zip(hgnc_df['source_id'],hgnc_df['match_freq']))\n",
    "        omim_df = paper_df[paper_df['source']=='OMIM']\n",
    "        omim_lst = list(zip(omim_df['source_id'],omim_df['match_freq']))\n",
    "        go_df = paper_df[paper_df['source']=='GO']\n",
    "        go_lst = list(zip(go_df['source_id'],go_df['match_freq']))\n",
    "        msh_df = paper_df[paper_df['source']=='MSH']\n",
    "        msh_lst = list(zip(msh_df['source_id'],msh_df['match_freq']))\n",
    "\n",
    "        pid_freq.append({'id':pid,\n",
    "                         f'{output_type}_hpo':hp_lst, \n",
    "                         f'{output_type}_hgnc':hgnc_lst,\n",
    "                         f'{output_type}_omim':omim_lst,\n",
    "                         f'{output_type}_go':go_lst,\n",
    "                         f'{output_type}_msh':msh_lst})\n",
    "        \n",
    "    term_freq_df = pd.DataFrame(pid_freq)\n",
    "    \n",
    "    term_freq_df[f'unique_{output_type}_hpo'] = [len(i) for i in term_freq_df[f'{output_type}_hpo']]\n",
    "    term_freq_df[f'unique_{output_type}_hgnc'] = [len(i) for i in term_freq_df[f'{output_type}_hgnc']]\n",
    "    term_freq_df[f'unique_{output_type}_omim'] = [len(i) for i in term_freq_df[f'{output_type}_omim']]\n",
    "    term_freq_df[f'unique_{output_type}_go'] = [len(i) for i in term_freq_df[f'{output_type}_go']]\n",
    "    term_freq_df[f'unique_{output_type}_msh'] = [len(i) for i in term_freq_df[f'{output_type}_msh']]\n",
    "    term_freq_df[f'unique_{output_type}_total'] = term_freq_df[f'unique_{output_type}_hpo']+term_freq_df[f'unique_{output_type}_hgnc']+term_freq_df[f'unique_{output_type}_omim']+term_freq_df[f'unique_{output_type}_go']+term_freq_df[f'unique_{output_type}_msh']\n",
    "    \n",
    "    return term_freq_df\n",
    "\n",
    "\n",
    "def retrieved_df_mm_output(tiab_output_dir, content_output_dir):\n",
    "    tiab_df = freq_per_paper_mm(tiab_output_dir,'tiab')\n",
    "    content_df = freq_per_paper_mm(content_output_dir,'content')\n",
    "    \n",
    "    tiab_content_df = pd.merge(tiab_df,content_df, how='outer')\n",
    "    \n",
    "    full_df = pd.merge(retrieved_df, tiab_content_df, how='right',left_index=True,right_on='id')\n",
    "    full_df = full_df.dropna(subset=['content_text'])\n",
    "    full_df = full_df.set_index('id')\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T06:29:30.603125Z",
     "start_time": "2021-10-13T06:28:27.657166Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df = retrieved_df_mm_output(\"path_to_tiab_mm_output\", \"path_to_content_text_mm_output\")\n",
    "\n",
    "full_df = full_df.drop(columns=['authors',\n",
    " 'journal',\n",
    " 'pub_type',\n",
    " 'pub_date',\n",
    " 'doi',\n",
    " 'issn',\n",
    " 'crossref',\n",
    " 'full_text_links',\n",
    " 'licenses',\n",
    " 'xml_parse_d',\n",
    " 'html_parse_d',\n",
    " 'pdf_parse_d',\n",
    " 'plain_parse_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T06:29:34.436791Z",
     "start_time": "2021-10-13T06:29:30.607933Z"
    }
   },
   "outputs": [],
   "source": [
    "# hpo terms which do not have root 'phenotypic abnormality' - need to remove\n",
    "parse_out = pickle.load(open('hp_ids_to_parse_out.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T06:33:42.141841Z",
     "start_time": "2021-10-13T06:33:41.817397Z"
    }
   },
   "outputs": [],
   "source": [
    "tiab_parsed = []\n",
    "for j in full_df['tiab_hpo']:\n",
    "    if type(j)==list:\n",
    "        tiab_parse_mod = [(i,v) for i,v in j if i not in parse_out]\n",
    "        tiab_parsed.append(tiab_parse_mod)\n",
    "    else:\n",
    "        tiab_parsed.append(0)\n",
    "    \n",
    "full_df['tiab_hpo'] = tiab_parsed\n",
    "\n",
    "content_parsed = []\n",
    "for j in full_df['content_hpo']:\n",
    "    parse_mod = [(i,v) for i,v in j if i not in parse_out]\n",
    "    content_parsed.append(parse_mod)\n",
    "    \n",
    "full_df['content_hpo'] = content_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T06:38:04.079157Z",
     "start_time": "2021-10-13T06:38:02.439261Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(full_df,open('ret_mm_df.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
