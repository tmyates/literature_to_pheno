from ontobio.ontol_factory import OntologyFactory
import pickle
from collections import Counter
import pandas as pd


ont = OntologyFactory().create('hp.obo')

[root_all] = ont.search('All')
all_hpo = ont.descendants(root_all)

[root] = ont.search('Phenotypic abnormality')

hpo_plus_labels = [{'hpo_id':x,'hpo_term':ont.label(x)} for x in ont.descendants(root)]
hpo_labels_df = pd.DataFrame(hpo_plus_labels)

# parse out obsolete terms
obsolete_term_repl = []
    # obsolete terms with replacements
for hp in ont.all_obsoletes():
    if list(set(ont.replaced_by(hp,strict=False))) != []:
        obsolete_term_repl.append({hp:(list(set(ont.replaced_by(hp,strict=False)))[0])})

    # all obsolete terms to identify those without direct replacements if needed
all_obsoletes = ont.all_obsoletes()



# create list of hpo terms and their descendants including synonyms of each
def hpo_syn_descendants(hpo_string):
    [k] = ont.search(hpo_string)
    label_list = [f"{ont.label(x)}" for x in ont.descendants(k)]
    label_list.append(hpo_string)
    k_desc = ont.descendants(k)
    k_syn = []
    for hp in k_desc:
        synonym_list = []
        [term] = ont.search(hp)
        synonym_list = [syn.val.lower() for syn in ont.synonyms(term)]
        label_list = label_list + synonym_list
        label_list = [j.lower() for j in label_list]
    return label_list

truly_all_hpo = hpo_syn_descendants('All')

## parse mrconso

mrconso_lst = []
with open('PATH_TO_MRCONSO', 'r') as f:
    for line in f:
        if line.split('|')[11]=='HPO':
            mrconso_lst.append(line.split('|'))

mrconso_dicts = []
# get cui mapped to hpo term - there are lots of duplicates as includes synonyms 
for c in mrconso_lst:
    cui = c[0]
    hpo_term = c[14]
    hpo_id = c[13]
    conso_dict = {'cui':cui, 'hpo_id':hpo_id, 'hpo_term':hpo_term}
    mrconso_dicts.append(conso_dict)

mrconso_df = pd.DataFrame(mrconso_dicts)
# drop string name to avoid issue with synonyms - map back name of term later
mrconso_df = mrconso_df.drop('hpo_term',axis=1)
mrconso_df = mrconso_df.drop_duplicates()

#     replace obsolete terms with current one, doesn't include obsolete terms with no direct repl, 
# but none of these in mmdf currently

for index,row in mrconso_df.iterrows():
    if row['hpo_id'] in all_obsoletes:
        for i in obsolete_term_repl:
            for k,v in i.items():
                if k == row['hpo_id']:
                    row['hpo_id'] = v

cui_hpo_label_df = mrconso_df.merge(hpo_labels_df)
cui_hpo_unique = cui_hpo_label_df.drop_duplicates()


# map cuis with more than one associated hpo id
cui_dups = cui_hpo_unique[cui_hpo_unique.cui.duplicated(keep=False)]
cui_dups = pd.DataFrame(cui_dups.groupby(['cui']).hpo_id.apply(list))

cui_dups['mapped_hpo']='no_map'
root_descendants = ont.descendants(root)

for index,row in cui_dups.iterrows():
    if len(row['hpo_id'])==2:
                 # map descendant_ancestor hpo pairs back to ancestor
        if row['hpo_id'][1] in ont.descendants(row['hpo_id'][0]):
            cui_dups.loc[index,'mapped_hpo'] = row['hpo_id'][0]
        elif row['hpo_id'][0] in ont.descendants(row['hpo_id'][1]):
            cui_dups.loc[index,'mapped_hpo'] = row['hpo_id'][1]
 #             map back to common parent
        elif [i for i in ont.parents(row['hpo_id'][0])] in ont.parents(row['hpo_id'][1]):
            cui_dups.loc[index,'mapped_hpo'] =  ont.parents(row['hpo_id'][0])[0]
        elif [i for i in ont.parents(row['hpo_id'][1])] in ont.parents(row['hpo_id'][0]):
            cui_dups.loc[index,'mapped_hpo'] =  ont.parents(row['hpo_id'][0])[0]
#              map to nearest common ancestor
    else:
        for hp in ont.descendants(root):
            level_lst = []
            hp_levels = []
            if row['hpo_id'][0] in ont.descendants(hp) and row['hpo_id'][1] in ont.descendants(hp):
                for i in range(0,16):
                    if hp in ont.get_level(i):
                        hp_levels.append({hp:i})
                        level_lst.append(i)
                            for i in hp_levels:
                                for k,v in i.items():
                                    if v == max(level_lst):
                                        cui_dups.loc[index,'mapped_hpo'] = k

    
hpo_id_labels = []
for hpl in cui_dups['hpo_id']:
    hpl_labels = [ont.label(hp) for hp in hpl]
    hpo_id_labels.append(hpl_labels)
        

mapped_hpo_labels = [ont.label(mp) for mp in cui_dups['mapped_hpo']]

cui_dups['hpo_id_labels'] = hpo_id_labels
cui_dups['mapped_hpo_labels'] = mapped_hpo_labels

# df without dup cui 
cuiduplst =(list(cui_dups.index))
cuihpo_nodup = cui_hpo_unique.drop(cuiduplst)

cuihpo_nodup = cuihpo_nodup.drop('hpo_term',axis=1)
# need to use this method as drop_duplicates doesn't consider the index
cuihpo_nodup = cuihpo_nodup[~cuihpo_nodup.reset_index().duplicated().values]

cui_dup_mapped = cui_dups.drop('hpo_id',axis=1)
cui_dup_mapped = cui_dup_mapped.rename(columns={'mapped_hpo':'hpo_id'})

cui_fully_mapped = cuihpo_nodup.append(cui_dup_mapped)

pickle.dump(cui_fully_mapped,open('cui_fully_mapped.p','wb'))


# hp terms with commas in - cause issues with splitting trigger when parsing metamap output
hp_commas = hp_label_df[hp_label_df['hp_label'].str.contains(",")]
hp_commas['hp_label_no_comma'] = [re.sub(",","", i) for i in hp_commas['hp_label']]
pickle.dump(hp_commas,open('hp_commas.p','wb'))





